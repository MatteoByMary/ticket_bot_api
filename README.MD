# Support Ticket AI Assistant

API FastAPI pour l'analyse automatique et le suivi des tickets de support client.

##  FonctionnalitÃ©s

- **Analyse automatique** : GÃ©nÃ¨re des tickets structurÃ©s Ã  partir de messages clients
- **Questions de suivi** : Propose des questions intelligentes pour complÃ©ter les informations
- **Multi-backends** : Support Ollama et Mistral
- **API REST** : Endpoints simples et documentÃ©s
- **Docker Ready** : DÃ©ploiement containerisÃ©

##  Structure du projet

```
.
â”œâ”€â”€ main.py                    # Point d'entrÃ©e FastAPI
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ schemas.py            # ModÃ¨les Pydantic
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model_service.py      # Service IA
â”‚   â””â”€â”€ prompt_service.py     # Gestion des prompts
â”œâ”€â”€ requirements.txt          # DÃ©pendances Python
â”œâ”€â”€ Dockerfile               # Configuration Docker
â”œâ”€â”€ docker-compose.yml       # Orchestration complÃ¨te
â””â”€â”€ README.md               # Ce fichier
```

##  Installation

### Option 1: Installation locale

```bash
# Cloner le projet
git clone <votre-repo>
cd support-ticket-ai

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env selon vos besoins

# Lancer l'API
uvicorn main:app --reload
```

### Option 2: Docker Compose (RecommandÃ©)

```bash
# Lancer tout le stack (API + Ollama)
docker-compose up -d

# Voir les logs
docker-compose logs -f

# ArrÃªter
docker-compose down
```

##  Configuration

Variables d'environnement importantes :

| Variable | DÃ©faut | Description |
|----------|--------|-------------|
| `MODEL_BACKEND` | `ollama` | Backend IA (`ollama` ou `mistral`) |
| `OLLAMA_URL` | `http://localhost:11434/api/generate` | URL du service Ollama |
| `OLLAMA_MODEL_NAME` | `mistral:instruct` | ModÃ¨le Ollama Ã  utiliser |
| `CORS_ORIGINS` | `http://localhost:5173` | Origines CORS autorisÃ©es |

##  API Endpoints

### `POST /analyze`
Analyse un message client et gÃ©nÃ¨re un ticket structurÃ©.

**Body:**
```json
{
  "message": "Mon imprimante ne marche plus depuis ce matin",
  "history": ["Bonjour", "J'ai un problÃ¨me"]
}
```

**Response:**
```json
{
  "success": true,
  "data": "JSON du ticket gÃ©nÃ©rÃ©",
  "message": "Ticket analysÃ© avec succÃ¨s"
}
```

### `POST /followup`
GÃ©nÃ¨re une question de suivi pour complÃ©ter un ticket.

**Body:**
```json
{
  "ticket": {
    "titre": "ProblÃ¨me imprimante",
    "categorie": "[INCONNU]",
    "description": "Imprimante en panne"
  },
  "history": ["Bonjour"]
}
```

### `GET /health`
VÃ©rification de l'Ã©tat du service.

##  Tests

```bash
# Test de l'API
curl -X POST "http://localhost:8000/analyze" \
  -H "Content-Type: application/json" \
  -d '{"message": "Test message"}'

# Health check
curl http://localhost:8000/health
```

##  Docker

### Build manuel
```bash
docker build -t support-ticket-ai .
docker run -p 8000:8000 support-ticket-ai
```

### Avec Ollama
```bash
# DÃ©marrer Ollama
docker run -d -p 11434:11434 --name ollama ollama/ollama

# Installer un modÃ¨le
docker exec ollama ollama pull mistral:instruct

# DÃ©marrer l'API
docker run -p 8000:8000 --link ollama support-ticket-ai
```

##  Monitoring

- **Logs** : Les logs sont centralisÃ©s avec le module `logging`
- **Health Check** : Endpoint `/health` pour les probes
- **MÃ©triques** : Codes de retour HTTP standardisÃ©s

##  Gestion d'erreurs

L'API gÃ¨re :
-  Timeouts des services IA
-  Erreurs de connexion
-  Validation des donnÃ©es
-  Messages d'erreur explicites

##  SÃ©curitÃ©

- **CORS** : Configuration sÃ©curisÃ©e
- **Validation** : Tous les inputs sont validÃ©s
- **Timeouts** : Protection contre les appels longs
- **Logs** : Audit trail complet

##  Performance

- **Timeout** : 30s max pour les appels IA
- **Async** : Toutes les opÃ©rations sont asynchrones
- **Cache** : PrÃªt pour l'ajout de cache Redis

##  Contribution

1. Fork le projet
2. CrÃ©e une branche (`git checkout -b feature/amazing-feature`)
3. Commit tes changes (`git commit -m 'Add amazing feature'`)
4. Push (`git push origin feature/amazing-feature`)
5. Ouvre une Pull Request

## ðŸ“„ License

Ce projet est sous `LICENSE`.

##  Support

- **Documentation API** : http://localhost:8000/docs (Swagger)